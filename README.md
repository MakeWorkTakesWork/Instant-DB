# ðŸš€ Instant-DB: Documents to Searchable RAG Database in Minutes

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Tests](https://img.shields.io/badge/tests-pytest-green.svg)](https://github.com/MakeWorkTakesWork/Instant-DB)

Transform any collection of documents into a production-ready, searchable RAG database with semantic search capabilities. Perfect for sales teams, knowledge workers, and anyone who needs to make their documents AI-searchable.

## âš¡ What is Instant-DB?

Instant-DB takes your **existing document processing pipeline** and adds **intelligent graph memory** with advanced semantic search. Unlike simple vector databases, Instant-DB builds knowledge graphs that understand relationships, concepts, and context. In minutes, not days.

### **Input** â†’ **Output**
```
ðŸ“„ Documents (.pdf, .docx, .ppt)     â†’     ðŸ§  Intelligent Knowledge Graph
ðŸ“ Parsed Text & Metadata           â†’     ðŸ”— Entity Relationships & Concepts  
ðŸ”§ Manual Knowledge Management       â†’     âš¡ Graph-Enhanced Semantic Search
```

## ðŸŽ¯ Perfect For

- **ðŸ¢ SaaS Sales Teams**: Search across pitch decks, objection handling, product docs
- **ðŸ“š Knowledge Workers**: Research papers, documentation, meeting notes
- **ðŸŽ“ Students/Researchers**: Academic papers, study materials, personal notes
- **ðŸ’¼ Consultants**: Client materials, case studies, methodologies

## âœ¨ Key Features

### **ðŸ“Š Multiple Vector Database Support**
- **ChromaDB** - Best for most users (default)
- **FAISS** - High performance for large datasets  
- **SQLite** - Simple, portable for small collections

### **ðŸ§  Multiple Embedding Providers**
- **Sentence Transformers** - Free, runs locally
- **OpenAI Embeddings** - Premium quality, API-based

### **ðŸ”— Ready-to-Use Integrations**
- **Custom GPT** - Upload and use immediately
- **Local LLMs** - Ollama, LM Studio integration
- **API Server** - REST endpoints for custom apps
- **Export Formats** - Ready for LangChain, LlamaIndex

### **ðŸ§  Graph Memory Features**
- **Entity Extraction**: Automatically identifies people, products, metrics, concepts
- **Relationship Discovery**: Maps connections between entities across documents
- **Concept Formation**: Creates higher-level abstractions and memory clusters
- **Graph-Enhanced Search**: Finds answers using relationship reasoning
- **Context Awareness**: Understands how information relates to build insights

### **ðŸ“ˆ Production Features**
- Smart chunking with section awareness
- Relevance scoring and ranking
- Document type classification
- Metadata preservation
- Incremental updates
- Batch processing

## ðŸš€ Quick Start

### Installation

```bash
# Install Instant-DB
pip install instant-db

# Platform-specific setup for file type detection
# macOS
brew install libmagic

# Ubuntu/Debian
sudo apt-get install libmagic1

# Windows (recommended: use WSL2)
wsl --install
```

### Basic Usage

```bash
# Auto-detect and process all documents in a directory
instant-db process ./documents

# Search your knowledge base
instant-db search "machine learning optimization"

# Search with metadata filtering
instant-db search "pricing" --filter "file_type:pdf"
instant-db search "report" --filter "file_size_mb>10"

# Export for Custom GPT
instant-db export --format markdown
```

## ðŸ” Advanced Features

### Metadata Filtering System

Powerful document filtering based on comprehensive metadata:

```bash
# Filter by file type
instant-db process ./docs --filter "file_type:pdf"

# Filter by size and date
instant-db search "quarterly" --filter '[{"field": "file_size_mb", "operator": "gt", "value": 5}, {"field": "creation_year", "operator": "eq", "value": 2024}]'

# Available filter fields
instant-db search --show-filter-examples
```

**Supported Filter Fields:**
- `filename`, `file_type`, `file_extension`, `mime_type`
- `file_size`, `file_size_mb`
- `creation_date`, `modification_date`, `creation_year`, `creation_month`
- `age_days` (days since creation)
- `tags`, `author`, `encoding`

**Filter Operators:**
- `:` or `=` (equals), `!=` (not equals), `~` (contains)
- `^` (starts with), `$` (ends with), `>` `<` `>=` `<=` (comparison)

### Auto-Discovery

Smart document detection eliminates manual manifest creation:

```bash
# Before: Manual manifest required
instant-db create --source manifest.json

# After: Automatic discovery (default)
instant-db process ./documents
instant-db process ./docs --extensions .pdf .docx --exclude temp
instant-db process ./sales --max-file-size 50 --recursive
```

## ðŸ“‹ Complete Workflow Example

Starting from **raw documents** to **searchable database**:

```bash
# 1. Process documents (works with existing MegaParse outputs too!)
python instant_db.py process ./my-documents --batch

# 2. Search your knowledge base
python instant_db.py search "customer onboarding process"

# 3. Export for team use
python instant_db.py export --format custom-gpt
python instant_db.py export --format api-server

# 4. Get database stats
python instant_db.py stats
```

## ðŸ—ï¸ Architecture

```
Documents â†’ Text Extraction â†’ Smart Chunking â†’ Graph Memory Engine â†’ Intelligent Database
    â†“            â†“               â†“                    â†“                      â†“
Raw Files    Clean Text      Section-Aware      Entity Extraction      Knowledge Graph
(.pdf/.docx)  + Metadata     Chunks + Overlap   Relationships          + Vector Search
                                               Concept Formation       + Reasoning
```

## ðŸ“Š Performance Benchmarks

| Dataset Size | Processing Time | Search Time | Memory Usage |
|--------------|----------------|-------------|--------------|
| 10 documents | 2-5 minutes | <100ms | 100MB |
| 100 documents | 15-30 minutes | <200ms | 500MB |
| 1000+ documents | 1-3 hours | <300ms | 2GB |

## ðŸ” Search Quality Examples

**Query**: "How to handle pricing objections"

**Traditional keyword search** finds:
- âŒ Documents containing "pricing" AND "objections"

**Instant-DB graph-enhanced search** finds:
- âœ… "Addressing cost concerns with ROI data" (+ connected to ROI metrics)
- âœ… "When prospects have budget constraints" (+ related to budget processes)
- âœ… "Value-based selling techniques" (+ linked to product benefits)
- âœ… "Overcoming price resistance" (+ connected to competitive pricing)
- ðŸ§  **Plus relationship context**: Shows how pricing connects to products, competitors, and outcomes

## ðŸ› ï¸ Integration Options

### **ðŸ¤– Custom GPT (Easiest)**
```bash
python instant_db.py export --format custom-gpt
# Upload to https://chat.openai.com/gpts/editor
```

### **ðŸ  Local LLM (Most Private)**
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3.2

# Use with your database
python instant_db.py serve --llm ollama
```

### **ðŸŒ OpenAI API (Best Quality)**
```python
from instant_db import InstantDB

db = InstantDB("./my_database")
context = db.search("pricing objections", top_k=3)

# Send context + question to GPT-4
response = openai.chat.completions.create(...)
```

### **ðŸ”Œ API Server (For Apps)**
```bash
python instant_db.py serve --api
# REST API available at http://localhost:5000
```

## ðŸ“ Repository Structure

```
instant-db/
â”œâ”€â”€ instant_db/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ database.py          # Vector database management
â”‚   â”‚   â”œâ”€â”€ embeddings.py        # Embedding providers
â”‚   â”‚   â”œâ”€â”€ chunking.py          # Smart text chunking
â”‚   â”‚   â””â”€â”€ search.py            # Semantic search engine
â”‚   â”œâ”€â”€ integrations/
â”‚   â”‚   â”œâ”€â”€ custom_gpt.py        # Custom GPT export
â”‚   â”‚   â”œâ”€â”€ ollama.py            # Local LLM integration
â”‚   â”‚   â”œâ”€â”€ openai_api.py        # OpenAI API integration
â”‚   â”‚   â””â”€â”€ api_server.py        # REST API server
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ document.py          # Document processing
â”‚   â”‚   â”œâ”€â”€ megaparse.py         # MegaParse integration
â”‚   â”‚   â””â”€â”€ batch.py             # Batch processing
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py            # Configuration management
â”‚       â”œâ”€â”€ logging.py           # Logging utilities
â”‚       â””â”€â”€ stats.py             # Database statistics
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ sales_team_setup.py     # Sales team example
â”‚   â”œâ”€â”€ research_workflow.py    # Research workflow
â”‚   â””â”€â”€ custom_integration.py   # Custom integration example
â”œâ”€â”€ tests/
â”œâ”€â”€ docs/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ instant_db.py              # Main CLI interface
â””â”€â”€ README.md
```

## ðŸŽ¯ Use Cases

### **Sales Team Knowledge Base**
```bash
# Process all sales materials
python instant_db.py process ./sales-collateral --batch

# Search for specific scenarios
python instant_db.py search "competitive objections"
python instant_db.py search "ROI calculations" 
python instant_db.py search "pricing strategies"

# Export for team Custom GPT
python instant_db.py export --format custom-gpt --name "Sales Assistant"
```

### **Research Paper Collection**
```bash
# Process academic papers
python instant_db.py process ./research-papers --batch --embedding-provider openai

# Advanced search with filtering
python instant_db.py search "machine learning optimization" --document-type "Research Paper"
```

### **Company Knowledge Management**
```bash
# Process internal documentation
python instant_db.py process ./company-docs --batch

# Create API for internal tools
python instant_db.py serve --api --host 0.0.0.0
```

## ðŸ”„ Works With Existing Workflows

**Already using MegaParse?** Perfect! Instant-DB works with your existing outputs:
```bash
# Process existing MegaParse outputs
python instant_db.py process-megaparse ./processed-documents
```

**Have raw documents?** We'll handle the processing:
```bash
# Full pipeline from raw documents
python instant_db.py process ./raw-documents --include-parsing
```

## ðŸš€ Quick Start

### 1. Installation

```bash
# Install from source (recommended for now)
git clone https://github.com/MakeWorkTakesWork/Instant-DB.git
cd Instant-DB
pip install -e .

# Or with all optional dependencies
pip install -e ".[all]"
```

### 2. Initialize Your Project

```bash
# Create configuration and sample directories
instant-db init
```

### 3. Process Your Documents

```bash
# Single document
instant-db process document.pdf

# Entire directory 
instant-db process ./documents --batch

# With custom settings
instant-db process ./documents --batch --chunk-size 800 --workers 4
```

### 4. Search Your Knowledge Base

```bash
# Simple search
instant-db search "machine learning concepts"

# Interactive search mode
instant-db search --interactive

# Export for Custom GPT
instant-db export --format markdown --split-by-type
```

## ðŸ“„ License

MIT License - see LICENSE file for details.

## ðŸ¤ Contributing

We welcome contributions! See CONTRIBUTING.md for guidelines.

---

**Transform your documents into an intelligent, searchable knowledge base in minutes, not days.** 